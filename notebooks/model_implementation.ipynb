{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for POS Tagging\n",
    "\n",
    "## This section is for the development of the CRF Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import and download all the necessary dependancies if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/promiseabel/opt/anaconda3/lib/python3.9/site-packages (24.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sklearn-crfsuite in /Users/promiseabel/opt/anaconda3/lib/python3.9/site-packages (0.5.0)\n",
      "Requirement already satisfied: python-crfsuite>=0.9.7 in /Users/promiseabel/opt/anaconda3/lib/python3.9/site-packages (from sklearn-crfsuite) (0.9.11)\n",
      "Requirement already satisfied: scikit-learn>=0.24.0 in /Users/promiseabel/opt/anaconda3/lib/python3.9/site-packages (from sklearn-crfsuite) (1.0.2)\n",
      "Requirement already satisfied: tabulate>=0.4.2 in /Users/promiseabel/opt/anaconda3/lib/python3.9/site-packages (from sklearn-crfsuite) (0.8.10)\n",
      "Requirement already satisfied: tqdm>=2.0 in /Users/promiseabel/opt/anaconda3/lib/python3.9/site-packages (from sklearn-crfsuite) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /Users/promiseabel/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/promiseabel/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (1.9.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/promiseabel/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/promiseabel/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the sklearn-crfsuite package\n",
    "%pip install --upgrade pip\n",
    "%pip install sklearn-crfsuite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "import ast\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then prepare the data by retrieving it from the cleaned csv files, gathering the required data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_to_list_of_dicts(string):\n",
    "    feats_list = ast.literal_eval(string)\n",
    "\n",
    "    converted_feats = []\n",
    "    for feat in feats_list:\n",
    "        if feat == 'None':\n",
    "            converted_feats.append(None)\n",
    "        else:\n",
    "            converted_feats.append(ast.literal_eval(feat))\n",
    "    return converted_feats \n",
    "\n",
    "def convert_to_list(string):\n",
    "    return ast.literal_eval(string)\n",
    "\n",
    "# Add the project root directory to sys.path\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, '../'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Load training dataset\n",
    "file_path = os.path.join(project_root, 'data/cleaned/train_cleaned.csv')\n",
    "training_df = pd.read_csv(file_path, converters=\n",
    "                 {'tokens': convert_to_list, \n",
    "                  'lemmas': convert_to_list, \n",
    "                  'upos': convert_to_list, \n",
    "                  'xpos': convert_to_list, \n",
    "                  'feats': convert_to_list_of_dicts,\n",
    "                  'head': convert_to_list,\n",
    "                  'deprel': convert_to_list,\n",
    "                  'deps': convert_to_list,\n",
    "                  'misc': convert_to_list})\n",
    "\n",
    "required_headers = ['deps', 'misc', 'idx', 'text', 'head', 'deprel', 'upos']\n",
    "if all(header in training_df.columns for header in required_headers):\n",
    "    training_df = training_df.drop(columns=required_headers)\n",
    "else:\n",
    "    print(\"Already dropped the training header columns\")\n",
    "\n",
    "# Load test dataset\n",
    "file_path = os.path.join(project_root, 'data/cleaned/test_cleaned.csv')\n",
    "test_df = pd.read_csv(file_path, converters=\n",
    "                 {'tokens': convert_to_list, \n",
    "                  'lemmas': convert_to_list, \n",
    "                  'upos': convert_to_list, \n",
    "                  'xpos': convert_to_list, \n",
    "                  'feats': convert_to_list_of_dicts,\n",
    "                  'head': convert_to_list,\n",
    "                  'deprel': convert_to_list,\n",
    "                  'deps': convert_to_list,\n",
    "                  'misc': convert_to_list})\n",
    "\n",
    "if all(header in test_df.columns for header in required_headers):\n",
    "    test_df = test_df.drop(columns=required_headers)\n",
    "else:\n",
    "    print(\"Already dropped the test header columns\")\n",
    "\n",
    "# Load validation dataset\n",
    "file_path = os.path.join(project_root, 'data/cleaned/validation_cleaned.csv')\n",
    "validation_df = pd.read_csv(file_path, converters=\n",
    "                 {'tokens': convert_to_list, \n",
    "                  'lemmas': convert_to_list, \n",
    "                  'upos': convert_to_list, \n",
    "                  'xpos': convert_to_list, \n",
    "                  'feats': convert_to_list_of_dicts,\n",
    "                  'head': convert_to_list,\n",
    "                  'deprel': convert_to_list,\n",
    "                  'deps': convert_to_list,\n",
    "                  'misc': convert_to_list})\n",
    "\n",
    "if all(header in validation_df.columns for header in required_headers):\n",
    "    validation_df = validation_df.drop(columns=required_headers)\n",
    "else:\n",
    "    print(\"Already dropped the validation header columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep the data get a list of tokens,tags and features where at any index, they correspond to each other and we get rid of any 'None' POS Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 204609\n",
      "Number of XPOS tags: 204609\n",
      "Number of LEMMAS: 204609\n",
      "Number of FEATS: 204609\n",
      "Al NNP Al {'Number': 'Sing'}\n",
      "- HYPH - None\n",
      "Zaman NNP Zaman {'Number': 'Sing'}\n",
      ": : : None\n",
      "American JJ american {'Degree': 'Pos'}\n",
      "forces NNS force {'Number': 'Plur'}\n",
      "killed VBD kill {'Mood': 'Ind', 'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "Shaikh NNP Shaikh {'Number': 'Sing'}\n",
      "Abdullah NNP Abdullah {'Number': 'Sing'}\n",
      "al NNP al {'Number': 'Sing'}\n",
      "Number of tokens: 25097\n",
      "Number of XPOS tags: 25097\n",
      "Number of LEMMAS: 25097\n",
      "Number of FEATS: 25097\n",
      "What WP what {'PronType': 'Int'}\n",
      "if IN if None\n",
      "Google NNP Google {'Number': 'Sing'}\n",
      "Morphed VBD morph {'Mood': 'Ind', 'Tense': 'Past', 'VerbForm': 'Fin'}\n",
      "Into IN into None\n",
      "GoogleOS NNP GoogleOS {'Number': 'Sing'}\n",
      "? . ? None\n",
      "What WP what {'PronType': 'Int'}\n",
      "if IN if None\n",
      "Google NNP Google {'Number': 'Sing'}\n",
      "Number of tokens: 25150\n",
      "Number of XPOS tags: 25150\n",
      "Number of LEMMAS: 25150\n",
      "Number of FEATS: 25150\n",
      "From IN from None\n",
      "the DT the {'Definite': 'Def', 'PronType': 'Art'}\n",
      "AP NNP AP {'Number': 'Sing'}\n",
      "comes VBZ come {'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Tense': 'Pres', 'VerbForm': 'Fin'}\n",
      "this DT this {'Number': 'Sing', 'PronType': 'Dem'}\n",
      "story NN story {'Number': 'Sing'}\n",
      ": : : None\n",
      "President NNP President {'Number': 'Sing'}\n",
      "Bush NNP Bush {'Number': 'Sing'}\n",
      "on IN on None\n"
     ]
    }
   ],
   "source": [
    "# Remove None or empty string values from pos tags and corresponding tokens\n",
    "# This is necessary because the Universal POS tags are not available for all tokens\n",
    "\n",
    "def get_flattened_filtered_columns(df):\n",
    "    filtered_tokens = []\n",
    "    filtered_xpos_tags = []\n",
    "    filtered_lemmas = []\n",
    "    filtered_feats = []\n",
    "\n",
    "    for i in range(df['tokens'].size):\n",
    "        tags = df['xpos'][i]\n",
    "        tokens = df['tokens'][i]\n",
    "        lemmas = df['lemmas'][i]\n",
    "        features = df['feats'][i]\n",
    "        for token, tag, lemma, feature in zip(tokens, tags, lemmas, features):\n",
    "            if tag is not None and tag != \"\":\n",
    "                filtered_tokens.append(token)\n",
    "                filtered_xpos_tags.append(tag)\n",
    "                filtered_lemmas.append(lemma)\n",
    "                filtered_feats.append(feature)\n",
    "    \n",
    "    print(f\"Number of tokens: {len(filtered_tokens)}\")\n",
    "    print(f\"Number of XPOS tags: {len(filtered_xpos_tags)}\")\n",
    "    print(f\"Number of LEMMAS: {len(filtered_lemmas)}\")\n",
    "    print(f\"Number of FEATS: {len(filtered_feats)}\")\n",
    "    for i in range(10): \n",
    "        print(filtered_tokens[i], filtered_xpos_tags[i], filtered_lemmas[i], filtered_feats[i])\n",
    "\n",
    "    return filtered_tokens, filtered_xpos_tags, filtered_lemmas, filtered_feats\n",
    "\n",
    "trainingFilteredTokens, trainingFilteredTags, trainingFilteredLemmas, trainingFilteredFeats = get_flattened_filtered_columns(training_df)\n",
    "\n",
    "testFilteredTokens, testFilteredTags, testFilteredLemmas, testFilteredFeats = get_flattened_filtered_columns(test_df)\n",
    "\n",
    "validationFilteredTokens, validationFilteredTags, validationFilteredLemmas,  validationFilteredFeats = get_flattened_filtered_columns(validation_df)\n",
    "# Verify the lengths after filtering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in order to create the crf model, we need to extract features. We've decided to extract a reasonable amount of features as to prevent overfitting issues.\n",
    "\n",
    "# Which Features should I extract?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction function\n",
    "def extract_features(tokens, lemmas, feats, i):\n",
    "    token = tokens[i]\n",
    "    lemma = lemmas[i]\n",
    "    feature_dict = feats[i] if feats[i] is not None or \"\" else {}\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'token.lower()': token.lower(),\n",
    "        'token.isupper()': token.isupper(),\n",
    "        'token.istitle()': token.istitle(),\n",
    "        'token.isdigit()': token.isdigit(),\n",
    "        'prefix-1': token[:1],\n",
    "        'prefix-2': token[:2],\n",
    "        'prefix-3': token[:3],\n",
    "        'suffix-1': token[-1:],\n",
    "        'suffix-2': token[-2:],\n",
    "        'suffix-3': token[-3:],\n",
    "        'token.length': len(token),\n",
    "        'lemma': lemma.lower(),\n",
    "    }\n",
    "    if i > 0:\n",
    "        token1 = tokens[i-1]\n",
    "        lemma1 = lemmas[i-1]\n",
    "        features.update({\n",
    "            '-1:token.lower()': token1.lower(),\n",
    "            '-1:token.istitle()': token1.istitle(),\n",
    "            '-1:token.isupper()': token1.isupper(),\n",
    "            '-1:lemma': lemma1.lower(),\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(tokens)-1:\n",
    "        token1 = tokens[i+1]\n",
    "        lemma1 = lemmas[i+1]\n",
    "        features.update({\n",
    "            '+1:token.lower()': token1.lower(),\n",
    "            '+1:token.istitle()': token1.istitle(),\n",
    "            '+1:token.isupper()': token1.isupper(),\n",
    "            '+1:lemma': lemma1.lower(),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    features.update(feature_dict)  # Include morphological features\n",
    "\n",
    "    return [features]\n",
    "\n",
    "\n",
    "def extract_features_for_sentence(tokens, lemmas, feats):\n",
    "    return [extract_features(tokens, lemmas, feats, i) for i in range(len(tokens))]\n",
    "\n",
    "def get_labels(tags):\n",
    "    return [tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'bias': 1.0, 'token.lower()': 'al', 'token.isupper()': False, 'token.istitle()': True, 'token.isdigit()': False, 'prefix-1': 'A', 'prefix-2': 'Al', 'prefix-3': 'Al', 'suffix-1': 'l', 'suffix-2': 'Al', 'suffix-3': 'Al', 'token.length': 2, 'lemma': 'al', 'BOS': True, '+1:token.lower()': '-', '+1:token.istitle()': False, '+1:token.isupper()': False, '+1:lemma': '-', 'Number': 'Sing'}]\n",
      "['NNP']\n",
      "[{'bias': 1.0, 'token.lower()': '-', 'token.isupper()': False, 'token.istitle()': False, 'token.isdigit()': False, 'prefix-1': '-', 'prefix-2': '-', 'prefix-3': '-', 'suffix-1': '-', 'suffix-2': '-', 'suffix-3': '-', 'token.length': 1, 'lemma': '-', '-1:token.lower()': 'al', '-1:token.istitle()': True, '-1:token.isupper()': False, '-1:lemma': 'al', '+1:token.lower()': 'zaman', '+1:token.istitle()': True, '+1:token.isupper()': False, '+1:lemma': 'zaman'}]\n",
      "['HYPH']\n",
      "[{'bias': 1.0, 'token.lower()': 'zaman', 'token.isupper()': False, 'token.istitle()': True, 'token.isdigit()': False, 'prefix-1': 'Z', 'prefix-2': 'Za', 'prefix-3': 'Zam', 'suffix-1': 'n', 'suffix-2': 'an', 'suffix-3': 'man', 'token.length': 5, 'lemma': 'zaman', '-1:token.lower()': '-', '-1:token.istitle()': False, '-1:token.isupper()': False, '-1:lemma': '-', '+1:token.lower()': ':', '+1:token.istitle()': False, '+1:token.isupper()': False, '+1:lemma': ':', 'Number': 'Sing'}]\n",
      "['NNP']\n",
      "[{'bias': 1.0, 'token.lower()': ':', 'token.isupper()': False, 'token.istitle()': False, 'token.isdigit()': False, 'prefix-1': ':', 'prefix-2': ':', 'prefix-3': ':', 'suffix-1': ':', 'suffix-2': ':', 'suffix-3': ':', 'token.length': 1, 'lemma': ':', '-1:token.lower()': 'zaman', '-1:token.istitle()': True, '-1:token.isupper()': False, '-1:lemma': 'zaman', '+1:token.lower()': 'american', '+1:token.istitle()': True, '+1:token.isupper()': False, '+1:lemma': 'american'}]\n",
      "[':']\n",
      "[{'bias': 1.0, 'token.lower()': 'american', 'token.isupper()': False, 'token.istitle()': True, 'token.isdigit()': False, 'prefix-1': 'A', 'prefix-2': 'Am', 'prefix-3': 'Ame', 'suffix-1': 'n', 'suffix-2': 'an', 'suffix-3': 'can', 'token.length': 8, 'lemma': 'american', '-1:token.lower()': ':', '-1:token.istitle()': False, '-1:token.isupper()': False, '-1:lemma': ':', '+1:token.lower()': 'forces', '+1:token.istitle()': False, '+1:token.isupper()': False, '+1:lemma': 'force', 'Degree': 'Pos'}]\n",
      "['JJ']\n",
      "[{'bias': 1.0, 'token.lower()': 'forces', 'token.isupper()': False, 'token.istitle()': False, 'token.isdigit()': False, 'prefix-1': 'f', 'prefix-2': 'fo', 'prefix-3': 'for', 'suffix-1': 's', 'suffix-2': 'es', 'suffix-3': 'ces', 'token.length': 6, 'lemma': 'force', '-1:token.lower()': 'american', '-1:token.istitle()': True, '-1:token.isupper()': False, '-1:lemma': 'american', '+1:token.lower()': 'killed', '+1:token.istitle()': False, '+1:token.isupper()': False, '+1:lemma': 'kill', 'Number': 'Plur'}]\n",
      "['NNS']\n",
      "[{'bias': 1.0, 'token.lower()': 'killed', 'token.isupper()': False, 'token.istitle()': False, 'token.isdigit()': False, 'prefix-1': 'k', 'prefix-2': 'ki', 'prefix-3': 'kil', 'suffix-1': 'd', 'suffix-2': 'ed', 'suffix-3': 'led', 'token.length': 6, 'lemma': 'kill', '-1:token.lower()': 'forces', '-1:token.istitle()': False, '-1:token.isupper()': False, '-1:lemma': 'force', '+1:token.lower()': 'shaikh', '+1:token.istitle()': True, '+1:token.isupper()': False, '+1:lemma': 'shaikh', 'Mood': 'Ind', 'Tense': 'Past', 'VerbForm': 'Fin'}]\n",
      "['VBD']\n",
      "[{'bias': 1.0, 'token.lower()': 'shaikh', 'token.isupper()': False, 'token.istitle()': True, 'token.isdigit()': False, 'prefix-1': 'S', 'prefix-2': 'Sh', 'prefix-3': 'Sha', 'suffix-1': 'h', 'suffix-2': 'kh', 'suffix-3': 'ikh', 'token.length': 6, 'lemma': 'shaikh', '-1:token.lower()': 'killed', '-1:token.istitle()': False, '-1:token.isupper()': False, '-1:lemma': 'kill', '+1:token.lower()': 'abdullah', '+1:token.istitle()': True, '+1:token.isupper()': False, '+1:lemma': 'abdullah', 'Number': 'Sing'}]\n",
      "['NNP']\n",
      "[{'bias': 1.0, 'token.lower()': 'abdullah', 'token.isupper()': False, 'token.istitle()': True, 'token.isdigit()': False, 'prefix-1': 'A', 'prefix-2': 'Ab', 'prefix-3': 'Abd', 'suffix-1': 'h', 'suffix-2': 'ah', 'suffix-3': 'lah', 'token.length': 8, 'lemma': 'abdullah', '-1:token.lower()': 'shaikh', '-1:token.istitle()': True, '-1:token.isupper()': False, '-1:lemma': 'shaikh', '+1:token.lower()': 'al', '+1:token.istitle()': False, '+1:token.isupper()': False, '+1:lemma': 'al', 'Number': 'Sing'}]\n",
      "['NNP']\n",
      "[{'bias': 1.0, 'token.lower()': 'al', 'token.isupper()': False, 'token.istitle()': False, 'token.isdigit()': False, 'prefix-1': 'a', 'prefix-2': 'al', 'prefix-3': 'al', 'suffix-1': 'l', 'suffix-2': 'al', 'suffix-3': 'al', 'token.length': 2, 'lemma': 'al', '-1:token.lower()': 'abdullah', '-1:token.istitle()': True, '-1:token.isupper()': False, '-1:lemma': 'abdullah', '+1:token.lower()': '-', '+1:token.istitle()': False, '+1:token.isupper()': False, '+1:lemma': '-', 'Number': 'Sing'}]\n",
      "['NNP']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare the training data for CRF\n",
    "training_x = extract_features_for_sentence(trainingFilteredTokens, trainingFilteredLemmas, trainingFilteredFeats)\n",
    "training_y = [get_labels(tags) for tags in trainingFilteredTags]\n",
    "\n",
    "for i in range(10):\n",
    "    print(training_x[i])\n",
    "    print(training_y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the test data for CRF\n",
    "test_x = extract_features_for_sentence(testFilteredTokens, testFilteredLemmas, testFilteredFeats)\n",
    "test_y = [get_labels(tags) for tags in testFilteredTags]\n",
    "\n",
    "# Prepare the validation data for CRF\n",
    "validation_x = extract_features_for_sentence(validationFilteredTokens, validationFilteredLemmas, validationFilteredFeats)\n",
    "validation_y = [get_labels(tags) for tags in validationFilteredTags]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Let's train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=0.1, c2=0.1,\n",
       "    max_iterations=100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the CRF model\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(training_x, training_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/promiseabel/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/Users/promiseabel/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/promiseabel/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NNP      0.896     0.885     0.891      1997\n",
      "        HYPH      0.736     0.796     0.765        98\n",
      "           :      0.914     0.850     0.881       100\n",
      "          JJ      0.997     0.997     0.997      1560\n",
      "         NNS      0.978     0.981     0.980       905\n",
      "         VBD      1.000     1.000     1.000       529\n",
      "           ,      0.947     0.974     0.961       980\n",
      "          DT      0.993     0.997     0.995      1952\n",
      "          NN      0.932     0.941     0.936      3320\n",
      "          IN      0.978     0.978     0.978      2314\n",
      "           .      0.995     0.991     0.993      1451\n",
      "       -LRB-      1.000     1.000     1.000       114\n",
      "          MD      1.000     1.000     1.000       400\n",
      "          VB      1.000     1.000     1.000      1127\n",
      "         VBG      1.000     1.000     1.000       342\n",
      "         PRP      1.000     1.000     1.000      1426\n",
      "          TO      0.932     0.984     0.957       375\n",
      "       -RRB-      1.000     1.000     1.000       114\n",
      "         VBN      1.000     1.000     1.000       454\n",
      "          RP      0.798     0.772     0.785        92\n",
      "          CD      1.000     1.000     1.000       536\n",
      "         VBZ      1.000     1.000     1.000       578\n",
      "          RB      0.956     0.955     0.956      1272\n",
      "        NNPS      0.773     0.744     0.758        78\n",
      "         VBP      1.000     1.000     1.000       719\n",
      "        PRP$      1.000     1.000     1.000       329\n",
      "          CC      0.997     0.995     0.996       739\n",
      "          WP      0.947     0.957     0.952        93\n",
      "          EX      1.000     0.979     0.989        48\n",
      "         WDT      0.964     0.955     0.959       111\n",
      "         RBR      1.000     0.769     0.870        26\n",
      "         PDT      0.950     1.000     0.974        19\n",
      "         JJR      0.885     1.000     0.939        46\n",
      "         WRB      1.000     1.000     1.000        90\n",
      "         JJS      0.912     1.000     0.954        83\n",
      "          ``      0.835     0.742     0.786        89\n",
      "          ''      0.765     0.852     0.806        88\n",
      "         POS      1.000     1.000     1.000        72\n",
      "         RBS      0.800     0.600     0.686        20\n",
      "         WP$      0.000     0.000     0.000         0\n",
      "         ADD      1.000     0.938     0.968        97\n",
      "          FW      1.000     1.000     1.000        13\n",
      "          LS      0.750     1.000     0.857         3\n",
      "          UH      1.000     0.864     0.927       118\n",
      "         AFX      1.000     0.400     0.571         5\n",
      "           $      1.000     1.000     1.000        30\n",
      "         NFP      0.946     0.845     0.892       103\n",
      "         SYM      1.000     0.381     0.552        21\n",
      "          GW      0.500     0.350     0.412        20\n",
      "          XX      0.000     0.000     0.000         1\n",
      "\n",
      "   micro avg      0.968     0.968     0.968     25097\n",
      "   macro avg      0.902     0.869     0.878     25097\n",
      "weighted avg      0.968     0.968     0.967     25097\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/promiseabel/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/promiseabel/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/promiseabel/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/promiseabel/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predict on the test set\n",
    "y_pred = crf.predict(test_x)\n",
    "\n",
    "# Evaluate the model\n",
    "labels = list(crf.classes_)\n",
    "metrics.flat_f1_score(test_y, y_pred, average='weighted', labels=labels)\n",
    "\n",
    "# Print classification report\n",
    "print(metrics.flat_classification_report(test_y, y_pred, labels=labels, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j7/tpgdfswn2r31tk28rclvmx4r0000gn/T/ipykernel_4286/1115704906.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/j7/tpgdfswn2r31tk28rclvmx4r0000gn/T/ipykernel_4286/1115704906.py\u001b[0m in \u001b[0;36mplot_confusion_matrix\u001b[0;34m(test_y, y_pred, labels)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Plot the confusion matrix for the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0my_true_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0my_pred_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Plot the confusion matrix for the test set\n",
    "def plot_confusion_matrix(test_y, y_pred, labels):\n",
    "    y_true_flat = [item for sublist in y_true for item in sublist]\n",
    "    y_pred_flat = [item for sublist in y_pred for item in sublist]\n",
    "    \n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(y_true_flat, y_pred_flat, labels=labels)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=labels, yticklabels=labels, cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(test_y, y_pred, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict on the validation set\n",
    "y_pred = crf.predict(validation_x)\n",
    "\n",
    "# Evaluate the model\n",
    "labels = list(crf.classes_)\n",
    "metrics.flat_f1_score(validation_y, y_pred, average='weighted', labels=labels)\n",
    "\n",
    "# Print classification report\n",
    "print(metrics.flat_classification_report(validation_y, y_pred, labels=labels, digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
